{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wstęp do Uczenia Maszynowego \n",
    "##### Laboratorium 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Default = pd.read_csv(\"Default.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1\n",
    "-----\n",
    "Przygotujmy dane do dalszej pracy:\n",
    "\n",
    "a) zmienną objaśnianą jest `default`\n",
    "\n",
    "b) zmiennymi objaśniającymi, których będziemy używać są `student` i `income`\n",
    "\n",
    "c) zamień zmienną `student` na logiczną, 1 gdy przyjmuje wartość `Yes`, 0 gdy przyjmuje wartość `No`\n",
    "\n",
    "d) podziel dane na treningowe i testowe w proporcji 6:4 i ustaw parametr `random_state`=221123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Default` jest to symulowany zestaw danych zawierający informacje o dziesięciu tysiącach klientów, takie jak to, czy klient nie wywiązał się ze zobowiązań, czy jest studentem, średnie saldo utrzymywane przez klienta i dochód klienta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gdy klasy zmiennej odpowiedzi Y (tj. domyślnie = \"Tak\", domyślnie = \"Nie\") są dobrze rozdzielone, oszacowania parametrów dla modelu regresji logistycznej są zaskakująco niestabilne. LDA i QDA nie cierpią z powodu tego problemu.\n",
    "- Jeśli n jest małe, a rozkład predyktorów X jest w przybliżeniu normalny w każdej z klas, modele LDA i QDA są ponownie bardziej stabilne niż model regresji logistycznej.\n",
    "- LDA i QDA są często preferowane w stosunku do regresji logistycznej, gdy mamy więcej niż dwie klasy odpowiedzi - bez porządku (tj.: udar, przedawkowanie narkotyków i napad padaczkowy).\n",
    "- Zawsze dobrze jest porównać wyniki różnych technik analitycznych; może to pomóc w potwierdzeniu wyników lub podkreślić, w jaki sposób różne założenia modelowania i charakterystyki odkrywają nowe spostrzeżenia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2\n",
    "-----\n",
    "Policz udział każdej z klas w zbiorze danych. Policz średnie w podgrupach: dla zmiennej `student` względem y oraz dla zmiennej `balance` względem y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 3\n",
    "-----\n",
    "Przygotuj model `LinearDiscriminantAnalysis` dla zbioru treningowego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 4\n",
    "-----\n",
    "Na podstawie wyliczonych współczynników oblicz funkcję decyzyją dla obserwacji ze zbioru treningowego. Rezultaty przedstaw na wykresie w podziale na wartości zmiennej `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 5\n",
    "-----\n",
    "Wyznacz macierz pomyłek dla modelu `LDA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Niezbalansowane dane - jaką miarą mierzyć jakość modeli?\n",
    "https://miroslawmamczur.pl/niezbalansowane-dane/\n",
    "\n",
    "https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 6\n",
    "-----\n",
    "Weźmy pod uwagę zbiór danych `earthquake.txt`. Przygotuj model LDA. Wyznacz wartości `decision_function()` i narysuj wykres w podziale na klasy zmiennej `y`. Wyznacz macierz pomyłek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquake = pd.read_csv('earthquake.txt', sep = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Quadratic Discriminant Analysis (QDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 7\n",
    "-----\n",
    "Przygotuj dla danych z Zadania 6 model QDA. Wyznacz wartości `decision_function()` i narysuj wykres w podziale na klasy zmiennej `y`. Wyznacz macierz pomyłek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *** Linear and Quadratic Discriminant Analysis with covariance ellipsoid\n",
    "Na podstawie: https://scikit-learn.org/stable/auto_examples/classification/plot_lda_qda.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "cmap = colors.LinearSegmentedColormap(\n",
    "    \"red_blue_classes_new\",\n",
    "    {\n",
    "        \"red\": [(0, 1, 1), (1, 0.7, 0.7)],\n",
    "        \"green\": [(0, 0.7, 0.7), (1, 0.7, 0.7)],\n",
    "        \"blue\": [(0, 0.7, 0.7), (1, 1, 1)],\n",
    "    },\n",
    ")\n",
    "plt.cm.register_cmap(cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg\n",
    "\n",
    "\n",
    "def plot_data(lda, X, y, y_pred, fig_index):\n",
    "    splot = plt.subplot(1, 2, fig_index)\n",
    "   \n",
    "    tp = y == y_pred  # True Positive\n",
    "    tp0, tp1 = tp[y == 'equake'], tp[y == 'explosn'] #tutaj należy pamiętać o zmianie\n",
    "    X0, X1 = X[y == 'equake'], X[y == 'explosn'] # tutaj należy pamiętać o zmianie\n",
    "    X0_tp, X0_fp = X0[tp0], X0[~tp0]\n",
    "    X1_tp, X1_fp = X1[tp1], X1[~tp1]\n",
    "\n",
    "    # class 0: dots\n",
    "    plt.scatter(X0_tp[\"body\"], X0_tp[\"surface\"], marker=\".\", color=\"red\")\n",
    "    plt.scatter(X0_fp[\"body\"], X0_fp[\"surface\"], marker=\"x\", s=20, color=\"#990000\")  # dark red\n",
    "\n",
    "    # class 1: dots\n",
    "    plt.scatter(X1_tp[\"body\"], X1_tp[\"surface\"], marker=\".\", color=\"blue\")\n",
    "    plt.scatter(X1_fp[\"body\"], X1_fp[\"surface\"], marker=\"x\", s=20, color=\"#000099\")  # dark blue\n",
    "\n",
    "    # class 0 and 1 : areas\n",
    "    nx, ny = 200, 100\n",
    "    x_min, x_max = plt.xlim()\n",
    "    y_min, y_max = plt.ylim()\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, nx), np.linspace(y_min, y_max, ny))\n",
    "    Z = lda.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z[:, 1].reshape(xx.shape)\n",
    "    plt.pcolormesh(\n",
    "        xx, yy, Z, cmap=\"red_blue_classes_new\", norm=colors.Normalize(0.0, 1.0), zorder=0\n",
    "    )\n",
    "    plt.contour(xx, yy, Z, [0.5], linewidths=2.0, colors=\"white\")\n",
    "\n",
    "    # means\n",
    "    plt.plot(\n",
    "        lda.means_[0][0],\n",
    "        lda.means_[0][1],\n",
    "        \"*\",\n",
    "        color=\"yellow\",\n",
    "        markersize=15,\n",
    "        markeredgecolor=\"grey\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        lda.means_[1][0],\n",
    "        lda.means_[1][1],\n",
    "        \"*\",\n",
    "        color=\"yellow\",\n",
    "        markersize=15,\n",
    "        markeredgecolor=\"grey\",\n",
    "    )\n",
    "\n",
    "    return splot\n",
    "\n",
    "\n",
    "def plot_ellipse(splot, mean, cov, color):\n",
    "    v, w = linalg.eigh(cov)\n",
    "    u = w[0] / linalg.norm(w[0])\n",
    "    angle = np.arctan(u[1] / u[0])\n",
    "    angle = 180 * angle / np.pi  # convert to degrees\n",
    "    # filled Gaussian at 2 standard deviation\n",
    "    ell = mpl.patches.Ellipse(\n",
    "        mean,\n",
    "        2 * v[0] ** 0.5,\n",
    "        2 * v[1] ** 0.5,\n",
    "        angle=180 + angle,\n",
    "        facecolor=color,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    ell.set_clip_box(splot.bbox)\n",
    "    ell.set_alpha(0.2)\n",
    "    splot.add_artist(ell)\n",
    "    splot.set_xticks(())\n",
    "    splot.set_yticks(())\n",
    "\n",
    "\n",
    "def plot_lda_cov(lda, splot):\n",
    "    plot_ellipse(splot, lda.means_[0], lda.covariance_, \"red\")\n",
    "    plot_ellipse(splot, lda.means_[1], lda.covariance_, \"blue\")\n",
    "\n",
    "\n",
    "def plot_qda_cov(qda, splot):\n",
    "    plot_ellipse(splot, qda.means_[0], qda.covariance_[0], \"red\")\n",
    "    plot_ellipse(splot, qda.means_[1], qda.covariance_[1], \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), facecolor=\"white\")\n",
    "plt.suptitle(\n",
    "    \"Linear Discriminant Analysis vs Quadratic Discriminant Analysis\",\n",
    "    y=0.98,\n",
    "    fontsize=15,\n",
    ")\n",
    "\n",
    "from sklearn.discriminant_analysis import (\n",
    "    LinearDiscriminantAnalysis,\n",
    "    QuadraticDiscriminantAnalysis,\n",
    ")\n",
    "\n",
    "\n",
    "# Linear Discriminant Analysis\n",
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "y_pred = lda.fit(X, y).predict(X)\n",
    "splot = plot_data(lda, X, y, y_pred, fig_index=1)\n",
    "plot_lda_cov(lda, splot)\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "# Quadratic Discriminant Analysis\n",
    "qda = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "y_pred = qda.fit(X, y).predict(X)\n",
    "splot = plot_data(qda, X, y, y_pred, fig_index=2)\n",
    "plot_qda_cov(qda, splot)\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.92)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
